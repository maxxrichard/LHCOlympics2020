{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"LHCOlympics2020_kmeans_clustering.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"5JHOCZ2W6v9J","colab_type":"text"},"source":["# K-Means Clustering"]},{"cell_type":"markdown","metadata":{"id":"O_WH6Sve6v9K","colab_type":"text"},"source":["Importing all necessary Libraries"]},{"cell_type":"code","metadata":{"id":"5kNE9SUH6v9L","colab_type":"code","colab":{}},"source":["import h5py    \n","import numpy as np \n","import matplotlib.pyplot as plt\n","from pyjet import cluster,DTYPE_PTEPM\n","import pandas as pd\n","from matplotlib.pyplot import cm\n","from matplotlib.colors import LinearSegmentedColormap\n","import os\n","import sklearn\n","from sklearn.cluster import KMeans\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.preprocessing import scale\n","import sklearn.metrics as sm\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.decomposition import PCA\n","from yellowbrick.cluster import KElbowVisualizer\n","from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8e40YRF6v9O","colab_type":"text"},"source":["# Reading .h5 file"]},{"cell_type":"code","metadata":{"id":"sUskH1986v9O","colab_type":"code","colab":{}},"source":["def readHadrons(mytype, filename = 'hadron.h5'):\n","    savename = H5output + mytype + '_' + filename\n","    if not os.path.exists(savename):\n","        print('\\x1b[31m[Warn.]\\x1b[0m', savename, '\\x1b[31mNOT\\x1b[0m', 'found')\n","        return\n","    keys = []\n","    with h5py.File(savename, 'r') as f:\n","        keys = list(f)\n","    for key in keys:\n","        event = pd.read_hdf(savename, key=key)\n","        events_combined = event.T\n","        np.shape(events_combined)\n","        yield events_combined"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uj44o1fB6v9R","colab_type":"text"},"source":["# Elbow curve and K-Means clustering"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"KuDoixHv6v9S","colab_type":"code","colab":{}},"source":["H5output = '../h5files/'\n","for event in readHadrons('background'):\n","    feature = np.asarray(event)\n","    b = feature[[1,2],:]\n","    X = b.transpose()\n","    X1 = feature[1]\n","    Y1 = feature[2]\n","    X_std = StandardScaler().fit_transform(X)\n","    \n","    \n","    sse = []\n","    list_k = list(range(1, 10))\n","\n","    for k in list_k:\n","        km = KMeans(n_clusters=k)\n","        km.fit(X_std)\n","        sse.append(km.inertia_)\n","\n","    # Plot sse against k\n","    plt.figure(figsize=(4, 4))\n","    plt.plot(list_k, sse, '-o')\n","    plt.xlabel(r'Number of clusters *k*')\n","    plt.ylabel('Sum of squared distance')\n","    plt.title('Elbow curve', fontweight='bold')\n","    \n","    \n","    k = 5\n","    fig = plt.figure(figsize=(20, 4))\n","    for j in range(1,k+1):\n","        km = KMeans(n_clusters=j, max_iter=100)\n","        km.fit(X_std)\n","        centroids = km.cluster_centers_\n","        #print(km.labels_)\n","        #print(centroids)\n","\n","        # Plot the clustered data\n","        color = ['green','blue','red','yellow','black','orange']\n","        for i in range(0,j):\n","            ax = fig.add_subplot(1, k, j)\n","            plt.scatter(X1[km.labels_ == i], Y1[km.labels_ == i], c=color[i], label=i+1)\n","            #plt.scatter(centroids[i,0], centroids[i,1], marker='*', s=300, c='r', label='centroid')\n","        plt.legend()\n","        plt.xlabel('\\u03B7')\n","        plt.ylabel('\\u03A6')\n","        plt.title('k = '+str(j), fontweight='bold')\n","        ax.set_aspect('equal');"],"execution_count":0,"outputs":[]}]}